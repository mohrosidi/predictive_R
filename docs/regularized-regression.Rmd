---
title: "Regularized Regression"
author: "Moh. Rosidi"
date: "7/24/2020"
output: 
  html_document:
    number_sections: yes
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: no
    df_print: paged
    theme: yeti
    highlight: textmate
    css: assets/style.css
  pdf_document:
    toc: yes
    toc_depth: '3'
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# Dataset Ames

Sebuah dataset terkait data properti yang ada di Ames IA. Dataset ini memiliki 82 variabel dan 2930 baris. Untuk informasi lebih lanjut terkait dataset ini, kunjungin tautan berikut:

* <https://ww2.amstat.org/publications/jse/v19n3/decock/DataDocumentation.txt>
* <http://ww2.amstat.org/publications/jse/v19n3/decock.pdf>

# Persiapan {.tabset}

## Library

Terdapat beberapa paket yang digunakan dalam pembuatan model prediktif menggunakan *tree based algorithm*. Paket-paket ditampilkan sebagai berikut:

```{r import-lib}
# library pembantu
library(tidyverse)
library(rsample)
library(recipes)
library(DataExplorer)
library(skimr)
library(modeldata)

# library model
library(caret)
library(glmnet)

# paket penjelasan model
library(vip)
library(pdp)
```

**Paket Pembantu**

1. `tidyverse` : kumpulan paket dalam bidang data science
2. `rsample` : membantu proses *data splitting*
3. `recipes`: membantu proses data pra-pemrosesan
4. `DataExplorer` : EDA
5. `skimr` : membuat ringkasan data
6. `modeldata` : kumpulan dataset untuk membuat model *machine learning*

**Paket untuk Membangun Model**

1. `caret` : berisikan sejumlah fungsi yang dapat merampingkan proses pembuatan model regresi dan klasifikasi
2. `earth` : berisikan fungsi untuk membuat model *regularized regression*

**Paket Interpretasi Model**

1. `vip` : visualisasi *variable importance*
2. `pdp` : visualisasi plot ketergantungan parsial

## Import Dataset

Import dataset dilakukan dengan menggunakan fungsi `data()`. Fungsi ini digunakan untuk mengambil data yang ada dalam sebuah paket.

```{r import-data}
data("ames")
```


# Data Splitting

Proses *data splitting* dilakukan setelah data di import ke dalam sistem. Hal ini dilakukan untuk memastikan tidak adanya kebocoran data yang mempengaruhi proses pembuatan model. Data dipisah menjadi dua buah set, yaitu: *training* dan *test*. Data *training* adalah data yang akan kita gunakan untuk membentuk model. Seluruh proses sebelum uji model akan menggunakan data *training*. Proses tersebut, antara lain: EDA, *feature engineering*, dan validasi silang. Data *test* hanya digunakan saat kita akan menguji performa model dengan data baru yang belum pernah dilihat sebelumnya.

Terdapat dua buah jenis sampling pada tahapan *data splitting*, yaitu:

1. *random sampling* : sampling acak tanpa mempertimbangkan adanya strata dalam data
2. *startified random sampling* : sampling dengan memperhatikan strata dalam sebuah variabel.

Dalam proses pembentukan model kali ini, kita akan menggunakan metode kedua dengan tujuan untuk memperoleh distribusi yang seragam dari variabel target (`Sale_Price`).

```{r data-split}
set.seed(123)

split  <- initial_split(ames, prop = 0.7, strata = "Sale_Price")
ames_train  <- training(split)
ames_test   <- testing(split)
```

Untuk mengecek distribusi dari kedua set data, kita dapat mevisualisasikan distribusi dari variabel target pada kedua set tersebut.

```{r target-vis}
# training set
ggplot(ames_train, aes(x = Sale_Price)) + 
  geom_density() 
# test set
ggplot(ames_test, aes(x = Sale_Price)) + 
  geom_density() 
```


# Analisis Data Eksploratif

Analsiis data eksploratif (EDA) ditujukan untuk mengenali data sebelum kita menentukan algoritma yang cocok digunakan untuk menganalisa data lebih lanjut. EDA merupakan sebuah proses iteratif yang secara garis besar menjawab beberapa pertanyaan umum, seperti:

1. Bagaimana distribusi data pada masing-masing variabel?
2. Apakah terdapat asosiasi atau hubungan antar variabel dalam data?

## Ringkasan Data

Terdapat dua buah fungsi yang digunakan dalam membuat ringkasan data, antara lain:

1. `glimpse()`: varian dari `str()` untuk mengecek struktur data. Fungsi ini menampilkan transpose dari tabel data dengan menambahkan informasi, seperti: jenis data dan dimensi tabel.
2. `skim()` : fungsi dari paket `skimr` untuk membuat ringkasan data yang lebih detail dibanding `glimpse()`, seperti: statistika deskriptif masing-masing kolom, dan informasi *missing value* dari masing-masing kolom.
3. `plot_missing()` : fungsi untuk memvisualisasikan persentase *missing value* pada masing-masing variabel atau kolom data


```{r glimpse}
glimpse(ames_train)
```

```{r skim}
skim(ames_train)
```

```{r missing-vis}
plot_missing(ames_train)
```

Berdasarkan ringkasan data yang dihasilkan, diketahui dimensi data sebesar 2053 baris dan 74 kolom. Dengan rincian masing-masing kolom, yaitu: 40 kolom dengan jenis data factor dan 34 kolom dengan jenis data numeric. Informasi lain yang diketahui adalah seluruh kolom dalam data tidak memiliki *missing value*.

## Variasi

Variasi dari tiap variabel dapat divisualisasikan dengan menggunakan histogram (numerik) dan baplot (kategorikal).

```{r hist}
plot_histogram(ames_train, ncol = 2L, nrow = 2L)
```

```{r bar}
plot_bar(ames_train, ncol = 2L, nrow = 2L)
```

Berdasarkan hasil visualisasi diperoleh bahwa sebagian besar variabel numerik memiliki distribusi yang tidak simetris. Sedangkan pada variabel kategorikal diketahui bahwa terdapat beberapa variabel yang memiliki variasi rendah atau mendekati nol. Untuk mengetahui variabel dengan variabilitas mendekati nol atau nol, dapat menggunakan sintaks berikut:

```{r nzv}
nzvar <- nearZeroVar(ames_train, saveMetrics = TRUE) %>% 
  rownames_to_column() %>% 
  filter(nzv)
nzvar
```

Berikut adalah ringkasan data pada variabel yang tidak memiliki variasi yang mendekati nol.

```{r wt-nzv}
without_nzvar <- select(ames_train, !nzvar$rowname)
skim(without_nzvar)
```

Berikut adalah tabulasi observasi pada masing-masing variabel yang memiliki jumlah kategori >= 10.

```{r count-nominal}
# MS_SubClass 
count(ames_train, MS_SubClass) %>% arrange(n)
# Neighborhood
count(ames_train, Neighborhood) %>% arrange(n)
# Neighborhood
count(ames_train, Exterior_1st) %>% arrange(n)
# Exterior_2nd
count(ames_train, Exterior_2nd) %>% arrange(n)
```

## Kovarian

Kovarian dapat dicek melalui visualisasi *heatmap* koefisien korelasi (numerik) atau menggunakan *boxplot* (kontinu vs kategorikal)

```{r heatmap}
plot_correlation(ames_train, type = "continuous", 
                 cor_args = list(method = "spearman"))
```

```{r boxplot}
plot_boxplot(ames_train, by = "Sale_Price", ncol = 2, nrow = 1)
```


# Regularized Regression

Tujuan dari regresi kuadrat terkecil (OLS biasa adalah untuk menemukan bidang yang meminimalkan jumlah kesalahan kuadrat (SSE) antara respons yang diamati dan yang diprediksi. Pada Gambar 1, ini berarti mengidentifikasi bidang yang meminimalkan garis abu-abu, yang mengukur jarak antara yang diamati dan respons yang diprediksi. Secara formal pernyataan tersebut dapat dituliskan dalam persamaan berikut:

$$
text{minimize} \bigg \{ SSE = \sum^n_{i=1} (y_i - \hat{y}_i)^2 \bigg \} \tag{1}
$$

Fungsi objektif OLS berkinerja cukup baik ketika data kita sejajar dengan asumsi kunci regresi OLS:

* Hubungan linear
* Normalitas multivarian
* Tidak ada autokorelasi
* Homoscedastic (varian konstan dalam residu)
* Ada lebih banyak pengamatan (n) daripada fitur (p) (n > p)
* Tidak ada atau sedikit multikolinearitas

Namun, untuk banyak set data kehidupan nyata kita memiliki data yang sangat luas, artinya kita memiliki sejumlah besar fitur (p) yang kita yakini informatif dalam memprediksi beberapa hasil. Dengan meningkatnya p, kita dapat dengan cepat melanggar beberapa asumsi OLS dan kita membutuhkan pendekatan alternatif untuk memberikan solusi analitik prediktif. Secara khusus, ketika p bertambah ada tiga masalah utama yang paling sering kita hadapi:

* **Multikolinearitas** : Ketika p meningkat, kita lebih cenderung menangkap beberapa fitur yang memiliki multikolinieritas. Ketika multikolinieritas ada, kita sering melihat variabilitas tinggi dalam koefisien kita.
* **Penyelesaian tidak mencukupi** : Ketika jumlah fitur melebihi jumlah pengamatan (p> n), matriks solusi OLS tidak dapat dibalik. Ini menyebabkan masalah signifikan karena artinya: (1) Estimasi kuadrat-terkecil tidak unik. Bahkan, ada satu set solusi tak terbatas yang tersedia dan sebagian besar solusi ini sesuai dengan data. (2) Dalam banyak kasus, hasilnya tidak layak secara komputasi.
* **Interpretabilitas** : Dengan sejumlah besar fitur, kita sering ingin mengidentifikasi subset yang lebih kecil dari fitur-fitur ini yang menunjukkan efek terkuat. Intinya, kita terkadang lebih suka teknik *feature selection*. Salah satu pendekatan untuk ini disebut *hard threshholding feature*, yang dapat dilakukan dengan pendekatan pemilihan model linier. Namun, pendekatan pemilihan model dapat menjadi tidak efisien secara komputasi, tidak dapat ditingkatkan dengan baik, dan mereka hanya menganggap fitur sebagai input atau output. Kita mungkin ingin menggunakan *soft threshholding approach* yang secara perlahan mendorong efek fitur ke nol. Seperti yang akan ditunjukkan, ini dapat memberikan pemahaman tambahan tentang sinyal prediksi.


## Validasi Silang dan Parameter Tuning

Langkah pertama yang perlu dilakukan dalam melakukan kegiatan validasi silang adalah menentukan spesifikasi parameter validasi silang. Fungsi `trainControl()` merupakan fungsi yang dapat kita gunakan untu menetukan metode validasi silang yang dilakukan dan spesifikasi terkait metode validasi silang yang digunakan.

```{r rr-cv}
# spesifikasi metode validasi silang
cv <- trainControl(
  # possible value: "boot", "boot632", "optimism_boot", "boot_all", "cv", 
  #                 "repeatedcv", "LOOCV", "LGOCV"
  method = "cv", 
  number = 10, 
  # repeats = 5,
  savePredictions = TRUE
)
```

Setelah parameter *tuning* dan validasi silang dispesifikasikan, proses training dilakukan menggunakan fungsi `train()`.

```{r rr-fit}
system.time(
rr_fit_cv <- train(
  Sale_Price~., 
  data = ames_train, 
  method = "glmnet", 
  trControl = cv, 
  tuneLength = 10,
  metric = "RMSE"
  )
)

rr_fit_cv

```

```{r}
rr_fit_cv$bestTune$lambda
```


Proses *training* berlangsung selama 16.579 detik. Model terbaik dipilih berdasarkan nilai **RMSE** terbesar. Berdasarkan kriteria tersebut model yang terpilih adalalah model yang memiliki nilai `alpha` = `r rr_fit_cv$bestTune$alpha` dan `lambda` = `r rr_fit_cv$bestTune$lambda`. Nilai **RMSE** rata-rata model terbaik adalah sebagai berikut:


```{r rr-rmse}
rr_rmse <- rr_fit_cv$results %>%
  arrange(RMSE) %>%
  slice(1) %>%
  select(RMSE) %>%
  pull()
rr_rmse
```

Berdasarkan hasil yang diperoleh, nilai **RMSE** rata-rata model sebesar `r rr_rmse`.

Visualisasi hubungan antar parameter  dan **RMSE** ditampilkan pada gambar berikut:

```{r rr-cv-vis, chace = TRUE}
# visualisasi
ggplot(rr_fit_cv)
```


## Model Akhir

Model terbaik dari hasil proses validasi silang selanjutnya diekstrak. Hal ini berguna untuk mengurangi ukuran model yang tersimpan. Secara default fungsi `train()` akan mengembalikan model dengan performa terbaik. Namun, terdapat sejumlah komponen lain dalam objek yang terbentuk, seperti: hasil prediksi, ringkasan training, dll. yang membuat ukuran objek menjadi besar. Untuk menguranginya, kita perlu mengambil objek model final dari objek hasil validasi silang.

```{r rr-final}
rr_fit <- rr_fit_cv$finalModel
```


Untuk melihat performa sebuah model regresi adalah dengan melihat visualisasi nilai residunya. Berikut adalah sintaks yang digunakan:

```{r rr-res-vis}
plot(rr_fit)
```

Model yang dihasilkan selanjutnya dapat kita uji lagi menggunakan data baru. Berikut adalah perhitungan nilai **RMSE** model pada data *test*.

```{r rr-rmse-test}
pred_test <- predict(rr_fit_cv, ames_test)

## RMSE
rmse <- RMSE(pred_test, ames_test$Sale_Price, na.rm = TRUE)
rmse
```

Berdasarkan hasil evaluasi diperoleh nilai akurasi sebesar `r rmse`


## Interpretasi Fitur

Untuk mengetahui variabel yang paling berpengaruh secara global terhadap hasil prediksi model, kita dapat menggunakan plot *variable importance*.

```{r rr-vip}
vi <- vip(rr_fit_cv, num_features = 10)
vi
```


Berdasarkan terdapat 4 buah variabel yang berpengaruh besar terhadap prediksi yang dihasilkan oleh model, antara lain: `r as.character(vi$data[1:4,1] %>% pull())`. 

